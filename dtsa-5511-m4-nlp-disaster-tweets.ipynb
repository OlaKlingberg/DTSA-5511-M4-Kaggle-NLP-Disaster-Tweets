{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":6068,"sourceType":"modelInstanceVersion","modelInstanceId":4689,"modelId":2821}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"!pip install -q keras-core --upgrade\n!pip install -q keras-nlp --upgrade\n!pip install -q tensorflow-text","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-19T14:27:04.601931Z","iopub.execute_input":"2024-08-19T14:27:04.602324Z","iopub.status.idle":"2024-08-19T14:27:42.922204Z","shell.execute_reply.started":"2024-08-19T14:27:04.602295Z","shell.execute_reply":"2024-08-19T14:27:42.920897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q contractions","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:27:42.924833Z","iopub.execute_input":"2024-08-19T14:27:42.925181Z","iopub.status.idle":"2024-08-19T14:27:55.028008Z","shell.execute_reply.started":"2024-08-19T14:27:42.925148Z","shell.execute_reply":"2024-08-19T14:27:55.026765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import contractions\nfrom textblob import TextBlob","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:27:55.029407Z","iopub.execute_input":"2024-08-19T14:27:55.029698Z","iopub.status.idle":"2024-08-19T14:27:55.034767Z","shell.execute_reply.started":"2024-08-19T14:27:55.029671Z","shell.execute_reply":"2024-08-19T14:27:55.033892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This sample uses Keras Core, the multi-backend version of Keras.\n# The selected backend is TensorFlow (other supported backends are 'jax' and 'torch')\nimport os\nos.environ['KERAS_BACKEND'] = 'tensorflow'","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:27:55.037583Z","iopub.execute_input":"2024-08-19T14:27:55.038373Z","iopub.status.idle":"2024-08-19T14:27:55.045563Z","shell.execute_reply.started":"2024-08-19T14:27:55.038341Z","shell.execute_reply":"2024-08-19T14:27:55.044672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q --upgrade keras","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:27:55.046803Z","iopub.execute_input":"2024-08-19T14:27:55.047601Z","iopub.status.idle":"2024-08-19T14:28:08.443313Z","shell.execute_reply.started":"2024-08-19T14:27:55.047560Z","shell.execute_reply":"2024-08-19T14:28:08.442354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You might have to restart the kernel here.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import display, FileLink\n\nfrom tqdm import tqdm\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.444988Z","iopub.execute_input":"2024-08-19T14:28:08.445385Z","iopub.status.idle":"2024-08-19T14:28:08.452946Z","shell.execute_reply.started":"2024-08-19T14:28:08.445350Z","shell.execute_reply":"2024-08-19T14:28:08.452004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras_core as keras\nimport keras_nlp\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.454646Z","iopub.execute_input":"2024-08-19T14:28:08.454949Z","iopub.status.idle":"2024-08-19T14:28:08.471367Z","shell.execute_reply.started":"2024-08-19T14:28:08.454917Z","shell.execute_reply":"2024-08-19T14:28:08.470623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load the data**","metadata":{}},{"cell_type":"code","source":"# Directories\ndata_dir = '/kaggle/input/nlp-getting-started/'","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.473809Z","iopub.execute_input":"2024-08-19T14:28:08.474106Z","iopub.status.idle":"2024-08-19T14:28:08.481349Z","shell.execute_reply.started":"2024-08-19T14:28:08.474084Z","shell.execute_reply":"2024-08-19T14:28:08.480538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(data_dir + \"train.csv\")\ntest_df = pd.read_csv(data_dir + \"test.csv\")\n\nprint('Training Set Size:', format(len(train_df)))\nprint('Test Set Size:', format(len(test_df)))","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.482430Z","iopub.execute_input":"2024-08-19T14:28:08.482690Z","iopub.status.idle":"2024-08-19T14:28:08.527119Z","shell.execute_reply.started":"2024-08-19T14:28:08.482668Z","shell.execute_reply":"2024-08-19T14:28:08.526277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_df))\nprint(len(train_df[train_df['keyword'].notna()]))","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.530609Z","iopub.execute_input":"2024-08-19T14:28:08.530936Z","iopub.status.idle":"2024-08-19T14:28:08.539079Z","shell.execute_reply.started":"2024-08-19T14:28:08.530913Z","shell.execute_reply":"2024-08-19T14:28:08.538238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.540200Z","iopub.execute_input":"2024-08-19T14:28:08.540484Z","iopub.status.idle":"2024-08-19T14:28:08.552892Z","shell.execute_reply.started":"2024-08-19T14:28:08.540462Z","shell.execute_reply":"2024-08-19T14:28:08.552055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Clean the data**","metadata":{}},{"cell_type":"code","source":"# Check for '%20' in the 'keyword' column\nprint(\"keyword column\")\ndisplay(train_df[train_df['keyword'].str.contains('%20', na = False)].head())\n\n# Check for '%20' in the 'text' column\nprint(\"text column\")\ndisplay(train_df[train_df['text'].str.contains('%20', na = False)].head())\n\n# Replace '%20' with ' ' in the keyword column\ntrain_df['keyword'] = train_df['keyword'].str.replace(r'%20', ' ', regex = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.554103Z","iopub.execute_input":"2024-08-19T14:28:08.554443Z","iopub.status.idle":"2024-08-19T14:28:08.589246Z","shell.execute_reply.started":"2024-08-19T14:28:08.554420Z","shell.execute_reply":"2024-08-19T14:28:08.588395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the keyword (if there is one) to the beginning of the text\ntrain_df['text'] = train_df['keyword'].fillna('') + ' ' + train_df['text']\n\n# Verify the results\ntrain_df[train_df['keyword'].notna()].head()","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.590391Z","iopub.execute_input":"2024-08-19T14:28:08.590729Z","iopub.status.idle":"2024-08-19T14:28:08.608988Z","shell.execute_reply.started":"2024-08-19T14:28:08.590700Z","shell.execute_reply":"2024-08-19T14:28:08.608153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove URLs\n# train_df['text'] = train_df['text'].str.replace(r'http\\S+|www\\S+|https\\S+', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.610097Z","iopub.execute_input":"2024-08-19T14:28:08.610438Z","iopub.status.idle":"2024-08-19T14:28:08.614385Z","shell.execute_reply.started":"2024-08-19T14:28:08.610407Z","shell.execute_reply":"2024-08-19T14:28:08.613470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove mentions\n# train_df['text'] = train_df['text'].str.replace(r'@\\w+', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.615569Z","iopub.execute_input":"2024-08-19T14:28:08.615936Z","iopub.status.idle":"2024-08-19T14:28:08.625024Z","shell.execute_reply.started":"2024-08-19T14:28:08.615906Z","shell.execute_reply":"2024-08-19T14:28:08.624161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove hashtags\n# train_df['text'] = train_df['text'].str.replace(r'#\\w+', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.626193Z","iopub.execute_input":"2024-08-19T14:28:08.626921Z","iopub.status.idle":"2024-08-19T14:28:08.635787Z","shell.execute_reply.started":"2024-08-19T14:28:08.626892Z","shell.execute_reply":"2024-08-19T14:28:08.634955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Expand contractions\n# train_df['text'] = train_df['text'].apply(lambda x: contractions.fix(x))","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.636835Z","iopub.execute_input":"2024-08-19T14:28:08.637109Z","iopub.status.idle":"2024-08-19T14:28:08.645676Z","shell.execute_reply.started":"2024-08-19T14:28:08.637087Z","shell.execute_reply":"2024-08-19T14:28:08.644850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Handle misspellings\n# train_df['text'] = train_df['text'].progress_apply(lambda x: str(TextBlob(x).correct()))","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.647559Z","iopub.execute_input":"2024-08-19T14:28:08.647858Z","iopub.status.idle":"2024-08-19T14:28:08.655149Z","shell.execute_reply.started":"2024-08-19T14:28:08.647836Z","shell.execute_reply":"2024-08-19T14:28:08.654276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simple cleaning\n# Removes all characters that are not upper- or lower-case English letters, or whitespaces.\n# Note, it till turn #BigStory into bigstory, i.e. it will not remove the phrase following the #.\ntrain_df['text'] = train_df['text'].str.replace(r'[^a-zA-Z\\s]', '', regex = True).str.lower()","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.656265Z","iopub.execute_input":"2024-08-19T14:28:08.656801Z","iopub.status.idle":"2024-08-19T14:28:08.716271Z","shell.execute_reply.started":"2024-08-19T14:28:08.656771Z","shell.execute_reply":"2024-08-19T14:28:08.715600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the cleaned data frame\ndisplay(train_df.head())\ntrain_df.to_csv('/kaggle/working/train_df.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.717103Z","iopub.execute_input":"2024-08-19T14:28:08.717360Z","iopub.status.idle":"2024-08-19T14:28:08.780027Z","shell.execute_reply.started":"2024-08-19T14:28:08.717339Z","shell.execute_reply":"2024-08-19T14:28:08.779339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reload the cleaned data fram\ntrain_df = pd.read_csv(\"/kaggle/working/train_df.csv\")\ndisplay(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.780969Z","iopub.execute_input":"2024-08-19T14:28:08.781250Z","iopub.status.idle":"2024-08-19T14:28:08.808448Z","shell.execute_reply.started":"2024-08-19T14:28:08.781227Z","shell.execute_reply":"2024-08-19T14:28:08.807628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Misclassified samples**","metadata":{}},{"cell_type":"code","source":"print(len(train_df))\nmislabeled_df = train_df.groupby(['text']).nunique().sort_values(by='target', ascending=False)\nmislabeled_tweets = mislabeled_df[mislabeled_df['target'] > 1]['target'].index.tolist()\n\ntrain_df = train_df[~train_df['text'].isin(mislabeled_tweets)]\nprint(len(train_df))","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.809361Z","iopub.execute_input":"2024-08-19T14:28:08.809597Z","iopub.status.idle":"2024-08-19T14:28:08.844985Z","shell.execute_reply.started":"2024-08-19T14:28:08.809576Z","shell.execute_reply":"2024-08-19T14:28:08.844171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"# Check if there is any clear difference in tweet-length distribution\n# between the two classes\ntrain_df['length'] = train_df['text'].apply(lambda x: len(x))\n\nprint(\"Tweet-length stats: class 0\")\nprint(train_df[train_df['target'] == 0]['length'].describe())\nprint()\n\n\nprint(\"Tweet-length stats: class 1\")\nprint(train_df[train_df['target'] == 1]['length'].describe())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T15:10:10.920153Z","iopub.execute_input":"2024-08-19T15:10:10.920764Z","iopub.status.idle":"2024-08-19T15:10:10.939968Z","shell.execute_reply.started":"2024-08-19T15:10:10.920734Z","shell.execute_reply":"2024-08-19T15:10:10.939004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['target_mean'] = train_df.groupby('keyword')['target'].transform('mean')\n\nfig = plt.figure(figsize=(8, 72), dpi=100)\n\nsns.countplot(y=train_df.sort_values(by='target_mean', ascending=False)['keyword'],\n              hue=train_df.sort_values(by='target_mean', ascending=False)['target'])\n\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=12)\nplt.legend(loc=1)\nplt.title('Target Distribution in Keywords')\n\nplt.show()\n\ntrain_df.drop(columns=['target_mean'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:08.900402Z","iopub.execute_input":"2024-08-19T14:28:08.900689Z","iopub.status.idle":"2024-08-19T14:28:11.889926Z","shell.execute_reply.started":"2024-08-19T14:28:08.900665Z","shell.execute_reply":"2024-08-19T14:28:11.889054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Take a sample of the data**\n\nTo speed up early hyper-parameter tuning, we'll start by training the model on just a portion of the training set, perhaps 10%. As we continue fine-tuning the hyper-parameters, we'll increase this portion to 25%, 50%, and finally to 100%.","metadata":{}},{"cell_type":"code","source":"# Take just a portion of the data, for early testing\nsample_fraction = 1 # Start with 0.1 and increase to 0.25, 0.5, and finally 1\ntrain_df_to_use = train_df.sample(frac = sample_fraction, random_state = 42)\n\n# Verify the sample\nprint(f'Full training set: {len(train_df)}')\nprint(f'Sampled training set: {len(train_df_to_use)}')","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:11.891281Z","iopub.execute_input":"2024-08-19T14:28:11.891720Z","iopub.status.idle":"2024-08-19T14:28:11.901054Z","shell.execute_reply.started":"2024-08-19T14:28:11.891686Z","shell.execute_reply":"2024-08-19T14:28:11.900174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split the data**","metadata":{}},{"cell_type":"code","source":"# TRAIN_SPLIT = 0.8\nVAL_SPLIT = 0.2\n\n# The \"text\" col holds the tweets; \n# the \"target\" col has 0 (not disaster-related) or 1 (disaster-related)\nX = train_df_to_use[\"text\"]\ny = train_df_to_use[\"target\"]\n\n# Split the training data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = VAL_SPLIT, random_state = 42)\n\n# Extract the tweets from the test data\nX_test = test_df[\"text\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:11.907406Z","iopub.execute_input":"2024-08-19T14:28:11.907721Z","iopub.status.idle":"2024-08-19T14:28:11.916285Z","shell.execute_reply.started":"2024-08-19T14:28:11.907695Z","shell.execute_reply":"2024-08-19T14:28:11.915476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16\n# STEPS_PER_EPOCH = len(X_train) // BATCH_SIZE\n\nEPOCHS = 20\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:11.917458Z","iopub.execute_input":"2024-08-19T14:28:11.917803Z","iopub.status.idle":"2024-08-19T14:28:11.926893Z","shell.execute_reply.started":"2024-08-19T14:28:11.917769Z","shell.execute_reply":"2024-08-19T14:28:11.926069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load a DistilBERT model.\npreset= \"distil_bert_base_en_uncased\"\n\n# Get the max-length of the tweets\nmax_length = train_df['text'].apply(lambda x: len(x)).max()\nprint(\"The longest tweet is\", max_length, \"characters long.\")\n\n# Preprocessor\npreprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n                                                                   sequence_length = max_length,\n                                                                   name = \"preprocessor_4_tweets\"\n                                                                  )\n\n# Pretrained classifier.\nclassifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,\n                                                               preprocessor = preprocessor,\n                                                               num_classes = 2)\n\nclassifier.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:11.927986Z","iopub.execute_input":"2024-08-19T14:28:11.929965Z","iopub.status.idle":"2024-08-19T14:28:30.724901Z","shell.execute_reply.started":"2024-08-19T14:28:11.929941Z","shell.execute_reply":"2024-08-19T14:28:30.724063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile\nclassifier.compile(\n    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), #'binary_crossentropy',\n    optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-6),\n    metrics= [\"accuracy\"]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:30.725960Z","iopub.execute_input":"2024-08-19T14:28:30.726259Z","iopub.status.idle":"2024-08-19T14:28:30.735031Z","shell.execute_reply.started":"2024-08-19T14:28:30.726233Z","shell.execute_reply":"2024-08-19T14:28:30.734116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model training**","metadata":{}},{"cell_type":"code","source":"# Early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights = True)\n\n# Fit\nhistory = classifier.fit(x = X_train,\n                         y = y_train,\n                         batch_size = BATCH_SIZE,\n                         epochs = EPOCHS,\n                         validation_data = (X_val, y_val),\n                         callbacks = [early_stopping]\n                        )","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:28:30.736140Z","iopub.execute_input":"2024-08-19T14:28:30.736413Z","iopub.status.idle":"2024-08-19T14:35:13.760014Z","shell.execute_reply.started":"2024-08-19T14:28:30.736371Z","shell.execute_reply":"2024-08-19T14:35:13.759189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the validation set\nscore, accuracy = classifier.evaluate(X_val, y_val, verbose = 2)\nprint(f\"Validation Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:35:13.761311Z","iopub.execute_input":"2024-08-19T14:35:13.761570Z","iopub.status.idle":"2024-08-19T14:35:19.641724Z","shell.execute_reply.started":"2024-08-19T14:35:13.761546Z","shell.execute_reply":"2024-08-19T14:35:19.640880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Prediction and Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"# Function that outputs a confusion matrix\ndef displayConfusionMatrix(y_true, y_pred, dataset):\n    disp = ConfusionMatrixDisplay.from_predictions(\n        y_true,\n        np.argmax(y_pred, axis = 1),\n        display_labels=[\"Not Disaster\", \"Disaster\"],\n        cmap=plt.cm.Blues\n    )\n\n    tn, fp, fn, tp = confusion_matrix(y_true, np.argmax(y_pred, axis=1)).ravel()\n    f1_score = tp / (tp+((fn+fp)/2))\n\n    disp.ax_.set_title(\"Confusion Matrix on \" + dataset + \" Dataset -- F1 Score: \" + str(f1_score.round(2)))","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:35:19.643033Z","iopub.execute_input":"2024-08-19T14:35:19.643703Z","iopub.status.idle":"2024-08-19T14:35:19.649815Z","shell.execute_reply.started":"2024-08-19T14:35:19.643665Z","shell.execute_reply":"2024-08-19T14:35:19.648904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the validation data\ny_val_pred = classifier.predict(X_val)\n\n# Output the confusion matrix for the validation data\ndisplayConfusionMatrix(y_val, y_val_pred, \"Validation\")","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:35:19.650846Z","iopub.execute_input":"2024-08-19T14:35:19.651093Z","iopub.status.idle":"2024-08-19T14:35:28.199308Z","shell.execute_reply.started":"2024-08-19T14:35:19.651072Z","shell.execute_reply":"2024-08-19T14:35:28.198369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predict on test data and generate submission file**","metadata":{}},{"cell_type":"code","source":"# Predict on the test data\ntest_pred = np.argmax(classifier.predict(X_test), axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:35:28.200625Z","iopub.execute_input":"2024-08-19T14:35:28.201426Z","iopub.status.idle":"2024-08-19T14:35:37.449307Z","shell.execute_reply.started":"2024-08-19T14:35:28.201389Z","shell.execute_reply":"2024-08-19T14:35:37.448372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the test_ids from the test data\ntest_ids = test_df[\"id\"]\n\n# Create a DataFrame\nsubmission = pd.DataFrame({\n    'id': test_ids,\n    'target': test_pred\n})\n\n# Take a look at the results\nprint(submission.head())\n\n# Generate a unique filename with a timestamp\ntimestamp = datetime.now().strftime('%Y-%m-%d_%H%M')\nfilename = f'dtsa-5511-m4-submission_{timestamp}.csv'\n\n# Save the DataFrame to a CSV file\nsubmission.to_csv(filename, index = False)\n\n# Generate a download link.\nFileLink(rf'{filename}')","metadata":{"execution":{"iopub.status.busy":"2024-08-19T14:35:37.450702Z","iopub.execute_input":"2024-08-19T14:35:37.450972Z","iopub.status.idle":"2024-08-19T14:35:37.466268Z","shell.execute_reply.started":"2024-08-19T14:35:37.450948Z","shell.execute_reply":"2024-08-19T14:35:37.465332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}